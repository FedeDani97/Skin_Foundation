{"cells":[{"cell_type":"markdown","source":["# DIFFUSION MODEL IMPLEMENTATION FOR DATA AUGMENTATION"],"metadata":{"id":"3nziyXIHbVCB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5bNVZ1T-wfAj"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"j3okTUhh8BVH"},"outputs":[],"source":["!pip install imagehash"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"5bu_AMeh9Lvs"},"outputs":[],"source":["!pip install lpips"]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"bvPVwq88bLg3"}},{"cell_type":"code","source":["import os, math, random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import cv2\n","from tqdm.auto import tqdm\n","from PIL import Image, ImageChops, ImageDraw, ImageFilter\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from torchvision.transforms import functional as F\n","import seaborn as sns\n","\n","from diffusers import (\n","    StableDiffusionImg2ImgPipeline,\n","    EulerAncestralDiscreteScheduler,\n","    DPMSolverMultistepScheduler,\n",")\n","import lpips\n","from skimage.metrics import structural_similarity as ssim"],"metadata":{"id":"EDIarboZWm7Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generation loop\n","\n"],"metadata":{"id":"7xyCILbAbTH9"}},{"cell_type":"markdown","source":["Comment on first trial\n","- Pass rate (31%): our QC was a bit strict for some classes, especially oiliness under blue-illumination (naturally lower contrast -> fails blur and sometimes looks “too similar” -> high SSIM).\n","- Oiliness artifacts: SD 1.5 doesn’t “know” blue-illum mode; with too much strength/CFG it tends to blow highlights into a uniform cyan wash / flashlight hotspot or collapse to a very dark frame."],"metadata":{"id":"XOqXsywvzXeU"}},{"cell_type":"code","source":["# ============================================================\n","# Proportional oversampling (+80%) with SD 1.5 img2img#\n","# ============================================================\n","\n","# --------------------\n","# Paths & run params\n","# --------------------\n","TRAIN_ORIGINAL_CSV = \"/content/drive/MyDrive/Skin_project/train_original.csv\"\n","OUT_DIR            = \"/content/drive/MyDrive/Skin_project/diffusion_oversample_70_2\"\n","LOG_CSV            = os.path.join(OUT_DIR, \"oversample_log_2.csv\")\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","TARGET_SD_SIZE = 512\n","GLOBAL_SEED = 2024\n","\n","# Oversampling: +80% per (feature, score) bucket\n","OVERSAMPLE_RATIO = 0.80\n","MAX_PER_BUCKET   = None\n","\n","FILTER_BY_QC = False\n","\n","# --------------------\n","# Compact prompts\n","# --------------------\n","SHOW_BLUE_OVERLAY  = True\n","MOISTURE_TONE_LOCK = True\n","\n","BASE_DEFAULT = \"macro skin patch, clinical close-up, high-detail microtexture, square crop, soft even lighting, natural color, no face\"\n","BASE_OIL     = \"macro skin patch, blue-illum dermatology imaging, square crop, soft even lighting, no face\"\n","BASE_MOIST   = \"macro skin patch, neutral non-blue lighting, square crop, soft even lighting, no face\"\n","BASE_RED     = \"macro skin patch with circular measurement patch in view, neutral lighting, soft even lighting, no face\"\n","\n","NEG_BASE = [\n","    \"face\",\"eyes\",\"nose\",\"mouth\",\"hair\",\"portrait\",\"selfie\",\"text\",\"logo\",\"watermark\",\n","    \"arrows\",\"grid\",\"legend\",\"scale bar\",\"numbers\",\"excessive blur\",\"heavy noise\",\"oversaturated\"\n","]\n","NEG_HP_EXTRA     = [\"blue tint\",\"solid blue blobs\",\"filled blue shapes\",\"heatmap\",\"colormap\"]\n","# Oiliness: harder negatives against wash/hotspot/exposure artifacts\n","NEG_OIL_EXTRA    = [\n","    \"heatmap\",\"colormap\",\"contour overlay\",\"uniform blue wash\",\"blue fog\",\"posterization\",\n","    \"overexposed\",\"blown highlights\",\"hotspot\",\"bloom\",\"lens flare\",\"vignette\",\"flashlight beam\",\"banding\",\"tiling\",\"haze\",\"overglow\"\n","]\n","NEG_MOIST_EXTRA  = [\"sweat droplets\",\"water droplets\",\"oily glare\",\"lotion smears\",\"blue illumination\",\"blue tint\"]\n","NEG_ELAST_EXTRA  = [\"oily glare\",\"sweat droplets\",\"deep wrinkles\",\"surgical tape marks\"]\n","NEG_RED_EXTRA    = [\"heatmap\",\"colormap\",\"legend\",\"scale bar\",\"blue cast\",\"false color\",\"uniform fill\",\"airbrushed\",\"gaussian blur\"]\n","\n","def join(t): return \", \".join(t)\n","\n","# Descriptors (oiliness now includes coverage/scatter)\n","def oiliness_desc(score:int):\n","    s = int(score)\n","    if s <= -1:\n","        return \"low oiliness; matte; sparse faint blue micro-specular points (<5% area); microtexture clearly visible\"\n","    if s == 0:\n","        return \"balanced oil; soft luster; scattered small blue highlights (10-20% area); microtexture visible\"\n","    if s == 1:\n","        return \"high oiliness; glossy; coherent blue specular regions (30-50% area) but pores and lines still visible\"\n","\n","score_desc = {\n","    \"texture\": {\n","        -1: \"rough texture; visible pores and micro ridges\",\n","         0: \"moderately even texture with some fine pores\",\n","         1: \"smooth even texture; refined pores\"\n","    },\n","    \"oiliness\": {\n","        -1: oiliness_desc(-1),\n","         0: oiliness_desc(0),\n","         1: oiliness_desc(1),\n","    },\n","    \"hyperpigmentation\": {\n","        -1: \"severe hyperpigmentation; dense clustered melanin microspots\" + (\", thin semi-transparent blue contours around spots\" if SHOW_BLUE_OVERLAY else \"\"),\n","         0: \"moderate hyperpigmentation; noticeable microspots; mild clustering\" + (\", moderate thin blue contours\" if SHOW_BLUE_OVERLAY else \"\"),\n","         1: \"minimal hyperpigmentation; few small, widely separated microspots\" + (\", few thin blue contours\" if SHOW_BLUE_OVERLAY else \"\"),\n","    },\n","    \"moisture\": {\n","        -1: \"low moisture; dehydrated; matte; fine lines and micro-cracks pronounced; narrow highlights\",\n","         0: \"average moisture; balanced hydration; soft highlights; clear microtexture\",\n","         1: \"high moisture; plump; diffuse sheen; broader low-contrast highlights; fine lines reduced\" + (\", keep input skin tone\" if MOISTURE_TONE_LOCK else \"\"),\n","    },\n","    \"elasticity\": {\n","        -1: \"low elasticity; slack microfolds; creases persist; broad dull highlights\",\n","         0: \"average elasticity; balanced micro-relief; moderate highlights\",\n","         1: \"high elasticity; taut microtexture; minimal creasing; tighter brighter highlights\",\n","    },\n","    \"redness\": {\n","        -1: \"strong diffuse erythema inside the circular patch; natural warm pink-red; microtexture visible\",\n","         0: \"moderate erythema inside the circular patch; gentle warm pink tone; microtexture visible; not uniform\",\n","         1: \"minimal erythema; patch mostly natural tone with subtle pinkness; microtexture preserved\",\n","    },\n","}\n","\n","def build_prompt(feature: str, score: int):\n","    desc = score_desc.get(feature, {}).get(int(score), \"\")\n","    if feature == \"oiliness\": base = BASE_OIL\n","    elif feature == \"moisture\": base = BASE_MOIST\n","    elif feature == \"redness\": base = BASE_RED\n","    else: base = BASE_DEFAULT\n","    prompt = f\"{base}, {desc}\".strip(\", \")\n","    neg = NEG_BASE.copy()\n","    if feature == \"texture\":\n","        prompt += \", sharp microtexture, fine micro-lines, no global blur\"\n","        neg += [\"flat uniform surface\"]\n","    if feature == \"hyperpigmentation\": neg += NEG_HP_EXTRA\n","    if feature == \"oiliness\":\n","        neg += NEG_OIL_EXTRA\n","        prompt += \", blue reflective highlights (not an overlay), natural exposure, no false color\"\n","    if feature == \"moisture\":\n","        neg += NEG_MOIST_EXTRA\n","        prompt += \", no hue shift\"\n","    if feature == \"elasticity\":\n","        neg += NEG_ELAST_EXTRA\n","        prompt += \", micro-relief indicates recoil, not oil shine\"\n","    if feature == \"redness\":\n","        neg += NEG_RED_EXTRA\n","        prompt += \", natural pink-red inside the circular patch; microtexture visible; not airbrushed\"\n","    return prompt, join(neg)\n","\n","# Token-safe trimming\n","PROMPT_MAX_TOKENS = 75\n","def trim_to_max_tokens(pipe, text, max_tokens=PROMPT_MAX_TOKENS):\n","    toks = pipe.tokenizer(text, truncation=True, max_length=max_tokens, return_tensors=\"pt\")\n","    return pipe.tokenizer.batch_decode(toks[\"input_ids\"], skip_special_tokens=True)[0]\n","\n","# --------------------\n","# Feature-specific hyperparams\n","# Oiliness uses lower strength/CFG by default\n","# --------------------\n","HPARAMS = {\n","    \"texture\":             dict(strength=0.28, cfg=4.8, steps=28),\n","    \"oiliness\":            dict(strength=0.23, cfg=3.8, steps=26),\n","    \"hyperpigmentation\":   dict(strength=0.35, cfg=5.2, steps=30),\n","    \"moisture\":            dict(strength=0.25, cfg=4.5, steps=28),\n","    \"elasticity\":          dict(strength=0.25, cfg=4.5, steps=28),\n","    \"redness\":             dict(strength=0.30, cfg=4.5, steps=30),\n","}\n","def jitter(feature, h):\n","    if feature == \"oiliness\":\n","        # added tighter range to avoid washouts\n","        return dict(\n","            strength=float(np.clip(h[\"strength\"] + np.random.uniform(-0.04, 0.04), 0.15, 0.30)),\n","            cfg=float(np.clip(h[\"cfg\"] + np.random.uniform(-0.6, 0.6), 2.8, 4.6)),\n","            steps=int(np.clip(h[\"steps\"] + np.random.choice([-2, 0, 2]), 24, 30)),\n","        )\n","    # default jitter\n","    return dict(\n","        strength=float(np.clip(h[\"strength\"] + np.random.uniform(-0.03, 0.03), 0.20, 0.55)),\n","        cfg=float(h[\"cfg\"] + np.random.uniform(-0.4, 0.4)),\n","        steps=int(np.clip(h[\"steps\"] + np.random.choice([-2, 0, 2]), 24, 36)),\n","    )\n","\n","# --------------------\n","# Helpers\n","# --------------------\n","def center_square_resize(img: Image.Image, size=TARGET_SD_SIZE) -> Image.Image:\n","    w,h = img.size; side = min(w,h); l=(w-side)//2; t=(h-side)//2\n","    return img.crop((l,t,l+side,t+side)).convert(\"RGB\").resize((size,size), Image.LANCZOS)\n","\n","def normalize_exposure(pil: Image.Image, clip_limit=2.0, tile_grid=(8,8)) -> Image.Image:\n","    \"\"\"CLAHE on L channel (LAB) – tames blown hotspots/dark frames typical in blue-illum.\"\"\"\n","    bgr = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)\n","    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n","    L, A, B = cv2.split(lab)\n","    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid)\n","    L2 = clahe.apply(L)\n","    lab2 = cv2.merge([L2, A, B])\n","    bgr2 = cv2.cvtColor(lab2, cv2.COLOR_LAB2BGR)\n","    return Image.fromarray(cv2.cvtColor(bgr2, cv2.COLOR_BGR2RGB))\n","\n","# --------------------\n","# Metrics & QC\n","# --------------------\n","LPIPS_FN = lpips.LPIPS(net='alex').to(DEVICE).eval()\n","\n","def to_lpips_tensor(pil_img, size=224):\n","    a = np.array(pil_img.convert(\"RGB\").resize((size,size), Image.LANCZOS))\n","    t = torch.tensor(a).permute(2,0,1).unsqueeze(0).float()/255.0\n","    return (t*2-1).to(DEVICE)\n","\n","def _lap_var(arr_rgb):\n","    g = cv2.cvtColor(arr_rgb, cv2.COLOR_RGB2GRAY)\n","    return float(cv2.Laplacian(g, cv2.CV_64F).var())\n","\n","def compute_metrics(pil_real: Image.Image, pil_syn: Image.Image, size=224):\n","    r = np.array(pil_real.convert(\"RGB\").resize((size,size), Image.LANCZOS))\n","    s = np.array(pil_syn.convert(\"RGB\").resize((size,size), Image.LANCZOS))\n","    # SSIM for logging\n","    try:\n","        ssim_val = float(ssim(r, s, channel_axis=2))\n","    except TypeError:\n","        ssim_val = float(ssim(r, s, multichannel=True))\n","    lp = float(LPIPS_FN(to_lpips_tensor(pil_real,size), to_lpips_tensor(pil_syn,size)).item())\n","    blur_real = _lap_var(r)\n","    blur_syn  = _lap_var(s)\n","    blur_ratio = float(blur_syn / (blur_real + 1e-9))\n","    return dict(ssim=ssim_val, lpips=lp, blur=blur_syn, blur_real=blur_real, blur_ratio=blur_ratio)\n","\n","# Oiliness specular coverage (blue-illum proxy)\n","def specular_coverage_blue(pil_img, size=224):\n","    a = np.array(pil_img.convert(\"RGB\").resize((size,size), Image.LANCZOS)).astype(np.float32)\n","    R, G, B = a[:,:,0], a[:,:,1], a[:,:,2]\n","    V = np.max(a, axis=2)\n","    mask = (B - np.maximum(R, G) > 15) & (V > 80)  # blue-dominant & bright\n","    return float(mask.mean())\n","\n","# LPIPS band + per-feature blur ratio + fallback floor\n","QC_DEFAULT = {\"lpips_min\": 0.18, \"lpips_max\": 0.65, \"blur_ratio_min\": 0.50, \"blur_floor\": 60.0}\n","FEATURE_QC = {\n","    \"elasticity\":         {\"lpips_min\": 0.18, \"lpips_max\": 0.65, \"blur_ratio_min\": 0.35, \"blur_floor\": 25.0},\n","    \"moisture\":           {\"lpips_min\": 0.18, \"lpips_max\": 0.65, \"blur_ratio_min\": 0.45, \"blur_floor\": 40.0},\n","    \"oiliness\":           {\"lpips_min\": 0.18, \"lpips_max\": 0.70, \"blur_ratio_min\": 0.50, \"blur_floor\": 60.0},\n","    \"texture\":            {\"lpips_min\": 0.22, \"lpips_max\": 0.60, \"blur_ratio_min\": 0.70, \"blur_floor\": 90.0},\n","    \"hyperpigmentation\":  {\"lpips_min\": 0.22, \"lpips_max\": 0.65, \"blur_ratio_min\": 0.70, \"blur_floor\": 100.0},\n","    \"redness\":            {\"lpips_min\": 0.18, \"lpips_max\": 0.65, \"blur_ratio_min\": 0.50, \"blur_floor\": 70.0},\n","}\n","\n","# Oiliness: acceptable specular coverage per label\n","OIL_COVERAGE_RANGE = {\n","    -1: (0.00, 0.12),\n","     0: (0.08, 0.35),\n","     1: (0.25, 0.60),\n","}\n","\n","def passes_qc(feature, score, m, syn_img=None):\n","    cfg = FEATURE_QC.get(feature, QC_DEFAULT)\n","    lp_ok   = (cfg[\"lpips_min\"] <= m[\"lpips\"] <= cfg[\"lpips_max\"])\n","    blur_ok = (m[\"blur_ratio\"] >= cfg[\"blur_ratio_min\"]) or (m[\"blur\"] >= cfg[\"blur_floor\"])\n","\n","    if feature == \"oiliness\" and syn_img is not None:\n","        cov = specular_coverage_blue(syn_img)\n","        lo, hi = OIL_COVERAGE_RANGE.get(int(score), (0.05, 0.60))\n","        cov_ok = (lo <= cov <= hi)\n","    else:\n","        cov, cov_ok = None, True\n","\n","    return bool(lp_ok and blur_ok and cov_ok), cov\n","\n","# --------------------\n","# Load CSV & build full table of usable rows\n","# --------------------\n","df = pd.read_csv(TRAIN_ORIGINAL_CSV)\n","\n","feature2imgcol = {\n","    \"moisture\": \"moisture_img\",\n","    \"oiliness\": \"oiliness_img\",\n","    \"elasticity\": \"elasticity_img\",\n","    \"texture\": \"texture_img\",\n","    \"redness\": \"redness_img\",\n","    \"hyperpigmentation\": \"hyperpigmentation_img\",\n","}\n","\n","def to_int(v, default=0):\n","    try: return int(v)\n","    except:\n","        try: return int(float(v))\n","        except: return default\n","\n","rows = []\n","for _, r in df.iterrows():\n","    pid = r.get(\"patient_id\")\n","    region = r.get(\"region\")\n","    for feat, col in feature2imgcol.items():\n","        pth = r.get(col)\n","        if isinstance(pth, str) and pth and os.path.exists(pth):\n","            sc = to_int(r.get(f\"{feat}_score\", 0), 0)\n","            rows.append((pid, region, feat, sc, pth))\n","base_df = pd.DataFrame(rows, columns=[\"patient_id\",\"region\",\"feature\",\"score\",\"image_path\"])\n","print(\"Usable base rows:\", len(base_df))\n","\n","# --------------------\n","# Oversampling plan\n","# --------------------\n","plan_rows = []\n","for (feat, sc), g in base_df.groupby([\"feature\",\"score\"]):\n","    n = len(g)\n","    n_new = int(math.ceil(n * OVERSAMPLE_RATIO))\n","    if MAX_PER_BUCKET is not None:\n","        n_new = min(n_new, MAX_PER_BUCKET)\n","    if n_new <= 0:\n","        continue\n","    sampled = g.sample(n_new, replace=True, random_state=GLOBAL_SEED)\n","    plan_rows.append(sampled)\n","plan_df = pd.concat(plan_rows, ignore_index=True) if plan_rows else pd.DataFrame(columns=base_df.columns)\n","print(\"Planned new generations:\", len(plan_df))\n","\n","# --------------------\n","# Load pipeline\n","# --------------------\n","pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n","    \"runwayml/stable-diffusion-v1-5\",\n","    torch_dtype=torch.float16 if DEVICE==\"cuda\" else torch.float32,\n",").to(DEVICE)\n","# default scheduler (used for non-oiliness)\n","pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n","pipe.safety_checker = lambda images, **kwargs: (images, [False]*len(images))\n","try:\n","    pipe.enable_attention_slicing(); pipe.enable_vae_tiling()\n","except: pass\n","\n","# scheduler config\n","_euler_cfg = pipe.scheduler.config\n","_dpm_cfg   = _euler_cfg\n","\n","# --------------------\n","# Generation loop\n","# --------------------\n","rng = torch.Generator(device=DEVICE).manual_seed(GLOBAL_SEED)\n","\n","records = []\n","for _, row in tqdm(plan_df.iterrows(), total=len(plan_df), desc=\"Oversampling\"):\n","    pid, region, feature, score, real_path = row.tolist()\n","    try:\n","        init_raw = Image.open(real_path)\n","    except Exception as e:\n","        print(\"open fail:\", real_path, e);\n","        continue\n","\n","    init_img = center_square_resize(init_raw, TARGET_SD_SIZE)\n","    if feature == \"oiliness\":\n","        init_img = normalize_exposure(init_img, clip_limit=2.0, tile_grid=(8,8))\n","\n","    p_full, n_full = build_prompt(feature, score)\n","    prompt  = trim_to_max_tokens(pipe, p_full)\n","    neg     = trim_to_max_tokens(pipe, n_full)\n","\n","    base_h = HPARAMS.get(feature, dict(strength=0.30, cfg=4.8, steps=28))\n","    h      = jitter(feature, base_h)\n","\n","    # different seed per sample for variety\n","    g = torch.Generator(device=DEVICE).manual_seed(random.randint(0, 2_000_000_000))\n","\n","    # switch scheduler per feature\n","    if feature == \"oiliness\":\n","        pipe.scheduler = DPMSolverMultistepScheduler.from_config(_dpm_cfg)\n","    else:\n","        pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(_euler_cfg)\n","\n","    out = pipe(\n","        prompt              = prompt,\n","        negative_prompt     = neg,\n","        image               = init_img,\n","        strength            = h[\"strength\"],\n","        guidance_scale      = h[\"cfg\"],\n","        num_inference_steps = h[\"steps\"],\n","        generator           = g\n","    )\n","    syn = out.images[0]\n","\n","    # metrics vs real (SSIM logged only)\n","    mets = compute_metrics(init_raw, syn)\n","    keep, cov = passes_qc(feature, score, mets, syn_img=syn)\n","\n","    if FILTER_BY_QC and not keep:\n","        continue\n","\n","    # save\n","    feat_dir = os.path.join(OUT_DIR, feature); os.makedirs(feat_dir, exist_ok=True)\n","    fname = f\"{feature}_{pid}_{region}_s{score}_aug{random.randint(100000,999999)}.png\"\n","    syn_path = os.path.join(feat_dir, fname)\n","    syn.save(syn_path)\n","\n","    records.append({\n","        \"patient_id\": pid,\n","        \"region\": region,\n","        \"feature\": feature,\n","        \"score\": score,\n","        \"real_path\": real_path,\n","        \"synthetic_path\": syn_path,\n","        \"strength\": h[\"strength\"],\n","        \"guidance_scale\": h[\"cfg\"],\n","        \"steps\": h[\"steps\"],\n","        \"prompt\": prompt,\n","        \"negative\": neg,\n","        \"ssim\": mets[\"ssim\"],\n","        \"lpips\": mets[\"lpips\"],\n","        \"blur\": mets[\"blur\"],\n","        \"blur_real\": mets[\"blur_real\"],\n","        \"blur_ratio\": mets[\"blur_ratio\"],\n","        \"specular_cov\": cov if feature==\"oiliness\" else np.nan,\n","        \"keep\": bool(keep),\n","    })\n","\n","# Log\n","log_df = pd.DataFrame(records)\n","log_df.to_csv(LOG_CSV, index=False)\n","print(f\"Wrote {len(log_df)} synthetic images to {OUT_DIR}\")\n","print(f\"Metrics log: {LOG_CSV}\")\n","print(\"Pass rate (LPIPS + blur-ratio QC):\", round(100.0 * (log_df['keep'].mean() if len(log_df) else 0), 1), \"%\")\n"],"metadata":{"id":"phEkd1E9YgU8","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CHECKS ON GENERATED IMAGES\n","\n","*  Fail/Keep rate\n","*  Visualisation"],"metadata":{"id":"wQ0LCe2jX8G5"}},{"cell_type":"code","source":["# --- Setup & imports --\n","import sys, subprocess, io, os, random\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","\n","try:\n","    from docx import Document\n","    from docx.shared import Inches, Pt\n","    from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n","except ImportError:\n","    # Attempt to install python-docx (works in Colab)\n","    print(\"Installing python-docx...\")\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"python-docx\", \"--quiet\"])\n","    from docx import Document\n","    from docx.shared import Inches, Pt\n","    from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n","\n","# =========================\n","# CONFIG\n","# =========================\n","OUT_DIR = \"/content/drive/MyDrive/Skin_project/diffusion_oversample_70_2\"\n","LOG_CSV = os.path.join(OUT_DIR, \"oversample_log_2.csv\")\n","REPORT_DOCX = os.path.join(OUT_DIR, \"oversample_report.docx\")\n","\n","# Whether to show images inline in the notebook and/or export them into Word\n","SHOW_INLINE = True\n","EXPORT_DOCX = True\n","\n","# Display/figure settings\n","MAX_SIDE = 480        # display size for each image in the pair (square)\n","RANDOM_SEED = 0       # seed for reproducible random picks\n","PAIR_FIGSIZE = (10, 5)  # inches\n","\n","# =========================\n","# Load and validate log\n","# =========================\n","assert os.path.exists(LOG_CSV), f\"Log not found: {LOG_CSV}\"\n","log = pd.read_csv(LOG_CSV)\n","\n","required_cols = {\"feature\",\"score\",\"keep\",\"real_path\",\"synthetic_path\"}\n","missing = required_cols - set(log.columns)\n","assert not missing, f\"Log is missing columns: {missing}\"\n","\n","# coerce keep -> bool\n","if log[\"keep\"].dtype != bool:\n","    log[\"keep\"] = log[\"keep\"].astype(str).str.lower().isin([\"true\",\"1\",\"yes\",\"y\"])\n","\n","# coerce score -> int (robustly)\n","def to_int(v, default=0):\n","    try:\n","        return int(v)\n","    except:\n","        try:\n","            return int(float(v))\n","        except:\n","            return default\n","log[\"score\"] = log[\"score\"].apply(to_int)\n","\n","# keep only rows with existing files\n","def _exists(p):\n","    return isinstance(p, str) and os.path.exists(p)\n","log = log[log[\"real_path\"].apply(_exists) & log[\"synthetic_path\"].apply(_exists)].reset_index(drop=True)\n","\n","print(f\"Rows with valid files: {len(log)}\")\n","if len(log) == 0:\n","    raise SystemExit(\"No rows to show. Double-check your OUT_DIR/LOG_CSV paths and that image files exist.\")\n","\n","# Ensure optional metrics are present\n","for col in [\"patient_id\",\"region\",\"ssim\",\"lpips\",\"blur\"]:\n","    if col not in log.columns:\n","        log[col] = np.nan\n","\n","# =========================\n","# Computations\n","# =========================\n","# 1) Counts per feature\n","feat_counts = (\n","    log.groupby([\"feature\",\"keep\"]).size()\n","       .unstack(fill_value=0)\n","       .rename(columns={True:\"kept\", False:\"failed\"})\n","       .reset_index()\n",")\n","feat_counts[\"total\"] = feat_counts[\"kept\"] + feat_counts[\"failed\"]\n","feat_counts[\"fail_rate_%\"] = (100.0 * feat_counts[\"failed\"] / feat_counts[\"total\"]).round(1)\n","feat_counts = feat_counts.sort_values(\"fail_rate_%\", ascending=False)\n","\n","print(\"\\n=== Fail/Keep per feature ===\")\n","display(feat_counts)\n","\n","# 2) Counts per (feature, score)\n","bucket_counts = (\n","    log.groupby([\"feature\",\"score\",\"keep\"]).size()\n","       .unstack(fill_value=0)\n","       .rename(columns={True:\"kept\", False:\"failed\"})\n","       .reset_index()\n",")\n","bucket_counts[\"total\"] = bucket_counts[\"kept\"] + bucket_counts[\"failed\"]\n","bucket_counts[\"fail_rate_%\"] = (100.0 * bucket_counts[\"failed\"] / bucket_counts[\"total\"]).round(1)\n","bucket_counts = bucket_counts.sort_values([\"feature\",\"score\"])\n","\n","print(\"\\n=== Fail/Keep per (feature, score) ===\")\n","display(bucket_counts)\n","\n","# =========================\n","# Word helpers\n","# =========================\n","def add_heading(doc, text, level=0):\n","    p = doc.add_heading(text, level=level)\n","    return p\n","\n","def add_df_table(doc, df: pd.DataFrame, caption: str = None):\n","    \"\"\"\n","    Insert a pandas DataFrame as a Word table with an optional caption.\n","    \"\"\"\n","    if caption:\n","        run = doc.add_paragraph().add_run(caption)\n","        run.bold = True\n","\n","    # Create table with header row + len(df) data rows\n","    rows, cols = df.shape\n","    table = doc.add_table(rows=rows+1, cols=cols)\n","    table.style = \"Light List Accent 1\" if \"Light List Accent 1\" in [s.name for s in doc.styles] else table.style\n","\n","    # Header\n","    for j, col_name in enumerate(df.columns):\n","        cell = table.cell(0, j)\n","        cell.text = str(col_name)\n","\n","    # Data\n","    for i in range(rows):\n","        for j in range(cols):\n","            val = df.iat[i, j]\n","            table.cell(i+1, j).text = \"\" if pd.isna(val) else str(val)\n","\n","    # Spacing after table\n","    doc.add_paragraph()\n","\n","def fig_pair_from_row(row, title_left=\"REAL\", title_right=\"SYN\"):\n","    \"\"\"\n","    Create a matplotlib figure with side-by-side images for a given row.\n","    Returns (fig, metadata_title) and DOES NOT show by default.\n","    \"\"\"\n","    try:\n","        real_img  = Image.open(row[\"real_path\"]).convert(\"RGB\")\n","        synth_img = Image.open(row[\"synthetic_path\"]).convert(\"RGB\")\n","    except Exception as e:\n","        print(\" could not open:\", row.get(\"synthetic_path\"), e)\n","        return None, None\n","\n","    # square-ish display without distorting too much (simple resize)\n","    real_img  = real_img.resize((MAX_SIDE, MAX_SIDE))\n","    synth_img = synth_img.resize((MAX_SIDE, MAX_SIDE))\n","\n","    fig, ax = plt.subplots(1, 2, figsize=PAIR_FIGSIZE)\n","    for a in ax: a.axis(\"off\")\n","    ax[0].imshow(real_img);  ax[0].set_title(title_left, fontsize=11)\n","    ax[1].imshow(synth_img); ax[1].set_title(title_right, fontsize=11)\n","    plt.tight_layout()\n","\n","    # Build a compact metadata string for caption\n","    pid = row.get(\"patient_id\", np.nan)\n","    reg = row.get(\"region\", np.nan)\n","    ssim  = row.get(\"ssim\",  np.nan)\n","    lpips = row.get(\"lpips\", np.nan)\n","    blur  = row.get(\"blur\",  np.nan)\n","\n","    meta = f\"pid:{pid}  reg:{reg}  \" \\\n","           f\"SSIM={ssim if pd.notna(ssim) else 'NA'}  \" \\\n","           f\"LPIPS={lpips if pd.notna(lpips) else 'NA'}  \" \\\n","           f\"BLUR={int(blur) if pd.notna(blur) else 'NA'}\"\n","    return fig, meta\n","\n","def add_figure_to_doc(doc, fig, width_inches=6.0, caption=None):\n","    \"\"\"\n","    Save a matplotlib figure to a BytesIO stream and insert into the Word doc.\n","    \"\"\"\n","    stream = io.BytesIO()\n","    fig.savefig(stream, format='png', bbox_inches=\"tight\", dpi=200)\n","    plt.close(fig)\n","    stream.seek(0)\n","    doc.add_picture(stream, width=Inches(width_inches))\n","    if caption:\n","        p = doc.add_paragraph(caption)\n","        p.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n","\n","# =========================\n","# Document creation\n","# =========================\n","if EXPORT_DOCX:\n","    doc = Document()\n","    # Title\n","    title = doc.add_paragraph()\n","    run = title.add_run(\"Diffusion Oversampling Report\")\n","    run.bold = True\n","    run.font.size = Pt(20)\n","\n","    doc.add_paragraph(f\"Source log: {LOG_CSV}\")\n","    doc.add_paragraph(f\"Total rows with valid files: {len(log)}\")\n","    doc.add_paragraph()\n","\n","    # Summary tables\n","    add_heading(doc, \"Summary by Feature\", level=1)\n","    add_df_table(doc, feat_counts, caption=\"Fail/Keep per feature\")\n","\n","    add_heading(doc, \"Summary by (Feature, Score)\", level=1)\n","    add_df_table(doc, bucket_counts, caption=\"Fail/Keep per (feature, score)\")\n","\n","# =========================\n","# 3) Random examples per (feature, score)\n","# =========================\n","random.seed(RANDOM_SEED)\n","np.random.seed(RANDOM_SEED)\n","\n","print(\"\\n=== Random examples per (feature, score) ===\")\n","for feat in sorted(log[\"feature\"].unique()):\n","    sub_feat = log[log[\"feature\"] == feat]\n","    scores = sorted(sub_feat[\"score\"].unique())\n","    for sc in scores:\n","        sub = sub_feat[sub_feat[\"score\"] == sc]\n","        failed = sub[sub[\"keep\"] == False]\n","        kept   = sub[sub[\"keep\"] == True]\n","\n","        header = f\"\\n— {feat} | score={sc} —  (kept={len(kept)}, failed={len(failed)})\"\n","        print(header)\n","\n","        if EXPORT_DOCX:\n","            add_heading(doc, f\"{feat} | score={sc}\", level=2)\n","            doc.add_paragraph(f\"(kept={len(kept)}, failed={len(failed)})\")\n","\n","        # FAILED example\n","        if len(failed) > 0:\n","            rowF = failed.sample(1, random_state=RANDOM_SEED).iloc[0]\n","            title_left  = f\"REAL  • pid:{rowF['patient_id']} reg:{rowF['region']}\"\n","            title_right = f\"SYN (failed) • SSIM={rowF.get('ssim',np.nan):.2f}  LPIPS={rowF.get('lpips',np.nan):.2f}  BLUR={rowF.get('blur',np.nan):.0f}\"\n","            fig, meta = fig_pair_from_row(rowF, title_left=title_left, title_right=title_right)\n","\n","            print(\"FAILED example:\")\n","            if fig is not None:\n","                if SHOW_INLINE:\n","                    plt.figure(fig.number)  # ensure current\n","                    plt.show()\n","                if EXPORT_DOCX:\n","                    add_figure_to_doc(doc, fig, width_inches=6.0, caption=f\"FAILED example — {meta}\")\n","        else:\n","            print(\"FAILED example: none in this bucket.\")\n","            if EXPORT_DOCX:\n","                doc.add_paragraph(\"FAILED example: none in this bucket.\")\n","\n","        # KEPT example\n","        if len(kept) > 0:\n","            rowK = kept.sample(1, random_state=RANDOM_SEED).iloc[0]\n","            title_left  = f\"REAL  • pid:{rowK['patient_id']} reg:{rowK['region']}\"\n","            title_right = f\"SYN (kept) • SSIM={rowK.get('ssim',np.nan):.2f}  LPIPS={rowK.get('lpips',np.nan):.2f}  BLUR={rowK.get('blur',np.nan):.0f}\"\n","            fig, meta = fig_pair_from_row(rowK, title_left=title_left, title_right=title_right)\n","\n","            print(\"KEPT example:\")\n","            if fig is not None:\n","                if SHOW_INLINE:\n","                    plt.figure(fig.number)\n","                    plt.show()\n","                if EXPORT_DOCX:\n","                    add_figure_to_doc(doc, fig, width_inches=6.0, caption=f\"KEPT example — {meta}\")\n","        else:\n","            print(\"KEPT example: none in this bucket.\")\n","            if EXPORT_DOCX:\n","                doc.add_paragraph(\"KEPT example: none in this bucket.\")\n","\n","# =========================\n","# Save document\n","# =========================\n","if EXPORT_DOCX:\n","    os.makedirs(os.path.dirname(REPORT_DOCX), exist_ok=True)\n","    doc.save(REPORT_DOCX)\n","    print(f\"\\n Word report saved to: {REPORT_DOCX}\")\n","\n","print(\"\\nDone.\")\n"],"metadata":{"id":"nD2zKOTrmCkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["######################################################################"],"metadata":{"id":"4qdbGrdeg3o-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creating 3 different datasets:\n","- real data\n","- real + synth\n","- synth"],"metadata":{"id":"-_1XDOMmKdRZ"}},{"cell_type":"code","source":["# ================================================\n","# Build 3 datasets:\n","#  - real-only            -> dataset_real_only.csv\n","#  - real + generated     -> dataset_real_plus_generated.csv\n","#  - generated-only       -> dataset_generated_only.csv\n","# Uses oversample_log.csv produced by the generator.\n","# ================================================\n","\n","import os\n","import pandas as pd\n","\n","# From your generator script\n","TRAIN_ORIGINAL_CSV = \"/content/drive/MyDrive/Skin_project/train_original.csv\"\n","OUT_DIR            = \"/content/drive/MyDrive/Skin_project/diffusion_oversample_70_2\"\n","LOG_CSV            = os.path.join(OUT_DIR, \"oversample_log_2.csv\")\n","\n","REAL_ONLY_CSV      = os.path.join(OUT_DIR, \"dataset_real_only.csv\")\n","REAL_PLUS_GEN_CSV  = os.path.join(OUT_DIR, \"dataset_real_plus_generated.csv\")\n","GEN_ONLY_CSV       = os.path.join(OUT_DIR, \"dataset_generated_only.csv\")\n","\n","# If True, only include synthetics with keep==True\n","ONLY_KEEP_SYNTHETIC = False\n","\n","# --- load inputs ---\n","df_orig = pd.read_csv(TRAIN_ORIGINAL_CSV)\n","log_df  = pd.read_csv(LOG_CSV)\n","\n","# Map feature -> image column and score column in your original CSV\n","feature2imgcol = {\n","    \"moisture\": \"moisture_img\",\n","    \"oiliness\": \"oiliness_img\",\n","    \"elasticity\": \"elasticity_img\",\n","    \"texture\": \"texture_img\",\n","    \"redness\": \"redness_img\",\n","    \"hyperpigmentation\": \"hyperpigmentation_img\",\n","}\n","feature2scorecol = {\n","    \"moisture\": \"moisture_score\",\n","    \"oiliness\": \"oiliness_score\",\n","    \"elasticity\": \"elasticity_score\",\n","    \"texture\": \"texture_score\",\n","    \"redness\": \"redness_score\",\n","    \"hyperpigmentation\": \"hyperpigmentation_score\",\n","}\n","\n","def _to_int(x, default=0):\n","    try: return int(x)\n","    except:\n","        try: return int(float(x))\n","        except: return default\n","\n","# --- build REAL rows ---\n","real_rows = []\n","for _, r in df_orig.iterrows():\n","    pid = r.get(\"patient_id\")\n","    region = r.get(\"region\")\n","    for feat, img_col in feature2imgcol.items():\n","        pth = r.get(img_col, \"\")\n","        if isinstance(pth, str) and len(pth) > 0 and os.path.exists(pth):\n","            sc = _to_int(r.get(feature2scorecol[feat], 0), 0)\n","            real_rows.append({\n","                \"patient_id\": pid,\n","                \"region\": region,\n","                \"feature\": feat,\n","                \"image_path\": pth,\n","                \"score\": sc,\n","                \"source\": \"real\",\n","            })\n","real_df = pd.DataFrame(real_rows)\n","real_df.to_csv(REAL_ONLY_CSV, index=False)\n","print(f\"✅ Real-only dataset: {len(real_df)} rows -> {REAL_ONLY_CSV}\")\n","\n","# --- build SYNTHETIC rows from the log ---\n","syn_df = log_df.copy()\n","if ONLY_KEEP_SYNTHETIC and \"keep\" in syn_df.columns:\n","    syn_df = syn_df[syn_df[\"keep\"] == True]\n","\n","# Normalize column names to the common schema\n","syn_df = syn_df.rename(columns={\n","    \"synthetic_path\": \"image_path\"\n","})\n","synthetic_df = syn_df[[\n","    \"patient_id\", \"region\", \"feature\", \"score\", \"image_path\"\n","]].copy()\n","synthetic_df[\"source\"] = \"synthetic\"\n","\n","# Optionally drop rows whose image files are missing (defensive)\n","synthetic_df = synthetic_df[synthetic_df[\"image_path\"].map(lambda p: isinstance(p, str) and os.path.exists(p))]\n","\n","# Save generated-only\n","synthetic_df.to_csv(GEN_ONLY_CSV, index=False)\n","print(f\"✅ Generated-only dataset: {len(synthetic_df)} rows -> {GEN_ONLY_CSV}\")\n","\n","# --- build REAL + GENERATED union ---\n","real_plus_gen = pd.concat([real_df, synthetic_df], ignore_index=True)\n","real_plus_gen.to_csv(REAL_PLUS_GEN_CSV, index=False)\n","print(f\"✅ Real + Generated dataset: {len(real_plus_gen)} rows -> {REAL_PLUS_GEN_CSV}\")\n","\n","# --- quick summaries ---\n","def summary(df, name):\n","    print(f\"\\n{name} — counts by (feature, score):\")\n","    print(df.groupby([\"feature\",\"score\"]).size().rename(\"n\").reset_index().pivot(index=\"feature\", columns=\"score\", values=\"n\").fillna(0).astype(int))\n","\n","summary(real_df, \"REAL\")\n","summary(synthetic_df, \"SYNTHETIC (kept only)\" if ONLY_KEEP_SYNTHETIC else \"SYNTHETIC (all)\")\n","summary(real_plus_gen, \"REAL + SYNTHETIC\")\n"],"metadata":{"id":"snbC70phKb-N"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMexUQJjd9N+H2/U0Fp2OZJ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}