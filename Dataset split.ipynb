{"cells":[{"cell_type":"markdown","source":["# DATASET SPLIT"],"metadata":{"id":"zqwUtWYAHUkh"}},{"cell_type":"markdown","metadata":{"id":"NQkFFegAI6o9"},"source":["Connecting to drive folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qeCuAE1O9liM"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","metadata":{"id":"Jmc6b6gkI9Xr"},"source":["Importing packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oklPoG8S96uW"},"outputs":[],"source":["import pandas as pd\n","from PIL import Image, ImageChops\n","from torchvision import transforms\n","import os\n","import matplotlib.pyplot as plt\n","import random\n","from torchvision.transforms import functional as F\n","import numpy as np\n","import seaborn as sns\n","import os, math, numpy as np, pandas as pd\n","from collections import Counter, defaultdict\n","from IPython.display import display"]},{"cell_type":"markdown","source":["Train-test split"],"metadata":{"id":"wNPE1GZ-HXTv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqbjvn5Z1Nrj"},"outputs":[],"source":["# ======================\n","# Configuration\n","# ======================\n","ORIG_CSV  = \"/content/drive/MyDrive/Skin_project/original_skin_dataset.csv\"\n","TRAIN_CSV = \"/content/drive/MyDrive/Skin_project/train_original.csv\"\n","TEST_CSV  = \"/content/drive/MyDrive/Skin_project/test_original.csv\"\n","\n","TEST_FRAC = 0.20\n","SEED = 42\n","OVERWRITE = True         # set True to recreate the split\n","CHECK_FILES = False        # True => only count rows whose image file exists\n","MIN_SUPPORT_TO_REQUIRE = 3 # require ≥1 test example for a (feature,label) if total support ≥ this\n","\n","\n","FEATURES = [\"texture\",\"hyperpigmentation\",\"oiliness\",\"moisture\",\"elasticity\"]\n","feature2imgcol = {\n","    \"moisture\": \"moisture_img\",\n","    \"oiliness\": \"oiliness_img\",\n","    \"elasticity\": \"elasticity_img\",\n","    \"texture\": \"texture_img\",\n","    \"redness\": \"redness_img\",\n","    \"hyperpigmentation\": \"hyperpigmentation_img\",\n","}\n","\n","# ======================\n","# Load full dataset\n","# ======================\n","df_orig = pd.read_csv(ORIG_CSV)\n","if \"patient_id\" not in df_orig.columns:\n","    raise ValueError(\" The dataset must have a 'patient_id' column!\")\n","\n","def _counts_table(dfX):\n","    rows = []\n","    for feat in FEATURES:\n","        img_col, lbl_col = feature2imgcol[feat], f\"{feat}_score\"\n","        if img_col not in dfX or lbl_col not in dfX:\n","            continue\n","        tmp = dfX[[img_col, lbl_col]].dropna()\n","        if CHECK_FILES:\n","            tmp = tmp[tmp[img_col].apply(lambda p: isinstance(p, str) and os.path.exists(p))]\n","        tmp = pd.to_numeric(tmp[lbl_col], errors=\"coerce\").dropna().astype(int)\n","        s = tmp.value_counts().sort_index()\n","        s.name = feat; rows.append(s)\n","    out = pd.DataFrame(rows).fillna(0).astype(int)\n","    out[\"total\"] = out.sum(axis=1)\n","    return out\n","\n","def _make_label_aware_group_split(df, test_frac=TEST_FRAC, seed=SEED):\n","    rng = np.random.RandomState(seed)\n","\n","    # Build patient -> Counter((feature,label) -> count), and global bin counts\n","    patient_bins = defaultdict(Counter)\n","    global_bins  = Counter()\n","    for _, r in df.iterrows():\n","        pid = str(r[\"patient_id\"])\n","        for feat in FEATURES:\n","            img_col, lbl_col = feature2imgcol[feat], f\"{feat}_score\"\n","            if img_col not in df or lbl_col not in df:\n","                continue\n","            y = r[lbl_col]; p = r[img_col]\n","            if pd.isna(y):\n","                continue\n","            if CHECK_FILES and not (isinstance(p, str) and os.path.exists(p)):\n","                continue\n","            try:\n","                y = int(round(float(y)))\n","            except Exception:\n","                continue\n","            patient_bins[pid][(feat, y)] += 1\n","            global_bins[(feat, y)] += 1\n","\n","    patients = list(patient_bins.keys())\n","    rng.shuffle(patients)\n","\n","    # Requirement: at least one test sample per bin if there is enough support\n","    req = {k: 1 if n >= MIN_SUPPORT_TO_REQUIRE else 0 for k, n in global_bins.items()}\n","\n","    # Greedy cover: pick patients that add the most unmet bins\n","    covered = Counter()\n","    test_patients = set()\n","\n","    def additional_gain(pid):\n","        gain = 0\n","        for k, c in patient_bins[pid].items():\n","            if req.get(k, 0) > 0 and covered[k] < req[k] and c > 0:\n","                gain += 1\n","        return gain\n","\n","    remaining = patients.copy()\n","    while True:\n","        unmet = [(k, req[k] - covered[k]) for k in req if covered[k] < req[k]]\n","        if not unmet:\n","            break\n","        best, best_gain = None, -1\n","        for pid in remaining:\n","            g = additional_gain(pid)\n","            if g > best_gain:\n","                best, best_gain = pid, g\n","        if best is None or best_gain <= 0:\n","\n","            missing = [k for k in req if covered[k] < req[k]]\n","            if missing:\n","                print(f\" Could not guarantee these bins in test (insufficient/overlapping support): {missing}\")\n","            break\n","        test_patients.add(best)\n","        for k, c in patient_bins[best].items():\n","            if req.get(k, 0) > 0 and covered[k] < req[k] and c > 0:\n","                covered[k] += 1\n","        remaining.remove(best)\n","\n","    # Fill to target #patients for test\n","    target_n = max(1, math.ceil(len(patients) * test_frac))\n","    rng.shuffle(remaining)\n","    for pid in remaining:\n","        if len(test_patients) >= target_n:\n","            break\n","        test_patients.add(pid)\n","\n","    is_test = df.patient_id.astype(str).isin(test_patients)\n","    df_test = df[is_test].reset_index(drop=True)\n","    df_train = df[~is_test].reset_index(drop=True)\n","\n","    print(f\"Selected {len(test_patients)} test patients \"\n","          f\"({len(test_patients)/len(patients):.1%} of patients). \"\n","          f\"Train rows: {len(df_train)}, Test rows: {len(df_test)}\")\n","\n","    # Report counts\n","    print(\"\\nTrain counts per feature/class:\")\n","    display(_counts_table(df_train))\n","    print(\"\\nTest counts per feature/class:\")\n","    display(_counts_table(df_test))\n","\n","    return df_train, df_test, test_patients\n","\n","# ======================\n","# Create or reuse split\n","# ======================\n","if OVERWRITE or not (os.path.exists(TRAIN_CSV) and os.path.exists(TEST_CSV)):\n","    df_train, df_test, test_pids = _make_label_aware_group_split(df_orig, TEST_FRAC, SEED)\n","    # Safety: no patient overlap\n","    overlap = set(df_train.patient_id.astype(str)) & set(df_test.patient_id.astype(str))\n","    assert not overlap, f\"Unexpected overlap in patient split: {overlap}\"\n","\n","    df_train.to_csv(TRAIN_CSV, index=False)\n","    df_test.to_csv(TEST_CSV, index=False)\n","    print(f\"\\nSaved split to:\\n  {TRAIN_CSV}\\n  {TEST_CSV}\")\n","else:\n","    df_train = pd.read_csv(TRAIN_CSV)\n","    df_test  = pd.read_csv(TEST_CSV)\n","    print(\"Using existing split (to keep test set consistent).\")\n","\n","\n","features_present = [c for c in feature2imgcol.values() if c in df_train.columns]\n","train_images_count = int(sum(df_train[c].notna().sum() for c in features_present))\n","test_images_count  = int(sum(df_test[c].notna().sum()  for c in features_present))\n","print(f\"\\n Train images: {train_images_count}, Test images: {test_images_count}\")\n"]},{"cell_type":"markdown","metadata":{"id":"_fwW4fxq7Bh2"},"source":["in the model implementation section we will merge the minumal classes for oiliness and moisture making them binary as to keep some support."]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOe6wv0++zC38d7QdV3Zkuz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}